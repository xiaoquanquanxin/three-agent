import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage, HumanMessage } from "@langchain/core/messages";
import { Command } from "langgraph";
import { AgentState } from "../agent_types/state";

export function createCalculatorAgent() {
  const llm = new ChatOpenAI({
    modelName: "gpt-4",
    temperature: 0
  });

  const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªæ•°å­¦è®¡ç®—ä¸“å®¶ã€‚
è¯·åˆ†æç”¨æˆ·çš„æ•°å­¦é—®é¢˜å¹¶ç»™å‡ºå‡†ç¡®çš„è®¡ç®—ç»“æœã€‚
åªè¿”å›è®¡ç®—è¿‡ç¨‹å’Œæœ€ç»ˆç­”æ¡ˆï¼Œä¿æŒç®€æ´ã€‚`;

  return async function calculatorAgent(state: AgentState): Promise<Command<"supervisor">> {
    console.log("\nğŸ§® è®¡ç®—å™¨æ™ºèƒ½ä½“ï¼šæ­£åœ¨å¤„ç†è®¡ç®—...");
    
    const userMessage = state.messages[0].content as string;
    
    // è°ƒç”¨ LLM å¤„ç†æ•°å­¦é—®é¢˜
    const messages = [
      new SystemMessage(systemPrompt),
      new HumanMessage(`è¯·è®¡ç®—ï¼š${userMessage}`)
    ];
    
    const response = await llm.invoke(messages);
    const result = response.content as string;

    return new Command({
      goto: "supervisor",
      update: {
        processed_image_url: `calculation_result: ${result}`,
        messages: [...state.messages, { 
          role: "system", 
          content: `è®¡ç®—å™¨æ™ºèƒ½ä½“ï¼š${result}` 
        }]
      }
    });
  };
}